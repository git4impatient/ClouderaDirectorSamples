#
# Copyright (c) 2018 Cloudera, Inc. All rights reserved.
#

# this config does not resize the root partition
# note the rootsize and normalize stanza need to appear in the common-instance-properties
# 


# WARNING - USING SPOT INSTANCES TO SAVE MONEY DURING TESTING
#  DO NOT DEPLOY YOUR LONG LIVED CLUSTER ON SPOT INSTANCES
#
# Simple AWS Cloudera Director configuration file with automatic role assignments
# that works as expected if you use a single instance type for all cluster nodes
#

#
# Cluster name
#

name: prodtls

#
# Cloud provider configuration (credentials, region or zone and optional default image)
#

provider {
    type: aws

    #
    # Get AWS credentials from the OS environment
    # See http://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html
    #
    # If specifying the access keys directly and not through variables, make sure to enclose
    # them in double quotes.
    #
    # Not needed when running on an instance launched with an IAM role.
    accessKeyId: ${?AWS_ACCESS_KEY_ID}
    secretAccessKey: ${?AWS_SECRET_ACCESS_KEY}

    #region: us-east-1
    region: ${?region}
    subnetId: ${?subnetId}
    securityGroupsIds: ${?securityGroupsIds}


#     accessKeyId: ${?AWS_ACCESS_KEY_ID}
#     secretAccessKey: ${?AWS_SECRET_ACCESS_KEY}

    #
    # ID of the Amazon AWS region to use
    # See: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html
    #


    #
    # Region endpoint (if you are using one of the Gov. regions)
    #

    # regionEndpoint: ec2.us-gov-west-1.amazonaws.com

    #
    # ID of the VPC subnet
    # See: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html
    #

    #subnetId: subnet-REPLACE-ME
#    subnetId: subnet-740e482e

    #
    # Comma separated list of security group IDs
    # See: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html
    #

    #securityGroupsIds: sg-REPLACE-ME
#    securityGroupsIds: sg-2b2dab5b

    #
    # A prefix that Cloudera Director should use when naming the instances (this is not part of the hostname)
    #

    instanceNamePrefix: martyTLScluster

    #
    # Whether to associate a public IP address with instances or not. If this is false
    # we expect instances to be able to access the internet using a NAT instance
    #
    # Currently the only way to get optimal S3 data transfer performance is to assign
    # public IP addresses to your instances and not use NAT (public subnet type of setup)
    #
    # See: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-ip-addressing.html
    #

     associatePublicIpAddresses: true

}

#
# SSH credentials to use to connect to the instances
#

ssh {
    username: ${?USER} # for RHEL image
    #privateKey: REPLACE-ME # with an absolute path to .pem file
    #privateKey: /home/centos/directorV2.pem
    privateKey: ${?path2privateKey}
}

#######################################################

#
# These instance properties will be applied to all instances.
#

common-instance-properties {
  #
  # Amazon Machine Image (AMI)
  #
  # See: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html
  #
  # Certain AMI virtualization types are incompatible with certain instance types.
  # HVM AMI types are recommended since they are compatible with most instance types.
  #
  # Compatibility matrix: https://aws.amazon.com/amazon-linux-ami/instance-type-matrix/
  #
  # Red Hat Enterprise Linux AMI IDs: http://aws.amazon.com/partners/redhat/
  #
  # We support RHEL and CentOS 6.5, 6.7, 6.8, 7.1, 7.2, and 7.3.
  # RHEL 7.2 is supported only for Cloudera Manager and CDH 5.7 and higher.
  # RHEL 6.8 and 7.3 are supported only for Cloudera Manager and CDH 5.10 and higher.
  #
  # To use Amazon EC2 D2 instances, you must run a minimum version of RHEL 6.7 or CentOS 6.7

#  image: ami-HVM-REPLACE-ME

  #
  # Name of the IAM Role to use for this instance type
  # http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html
  #

  # iamProfileName: iam-profile-REPLACE-ME

#  tags {
#    owner: ${?USER}
#  }

#  bootstrapScripts: ["""#!/bin/sh

# This is an embedded bootstrap script that runs as root and can be used to customize
# the instances immediately after boot and before any other Cloudera Altus Director action

# Use exit code 0 to indicate success
# Use exit code 91 indicate an unretryable failure
# Cloudera Altus Director will automatically retry script execution for all other exit codes

#echo 'Hello World!'
#exit 0

#"""]

  # For more complex scripts, embedded bootstrap scripts can be supplied via local
  # filesystem paths. They will run after any scripts supplied in the previous
  # bootstrapScripts section.
  # bootstrapScriptsPaths: ["/tmp/test-script.sh",
  #                         "/tmp/test-script.py"]
    #
    # Specify a size for the root volume (in GBs). Cloudera Director will automatically expand the
    # filesystem so that you can use all the available disk space for your application
    # See: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage_expand_partition.html
    #

    rootVolumeSizeGB: 153 # defaults to 50 GB if not specified

    #
    # Specify the type of the EBS volume used for the root partition. Defaults to gp2
    # See: http://aws.amazon.com/ebs/details/
    #

    # rootVolumeType: gp2 # OR standard (for EBS magnetic)


  #
  # Flag indicating whether to normalize the instance. Not setting normalization here implies that your
  # bootstrap script will take care of normalization. This is an advanced configuration that will require
  # assistance from Cloudera support.
  #
  # Defaults to true
  #

normalizeInstance: true

  #
  # Configuration allowing for granular control over the normalization steps of an instance.
  # By default, all of these steps are on. This is an advanced configuration. None of these steps
  # will run if normalizeInstance is set to false.
  #
  # Normalization includes:
  #   prewarming the parcel directory
  #   downloading, installing, and adjusting packages
  #   minimizing swappiness
  #   increasing the maximun number of open files
  #   resizing the root partition
  #   mounting ephemeral disks

 normalizationConfig {
   prewarmDirectory: true
   installPackages: true
   miscellaneousServiceAdjustment: true
   minimizeSwappiness: true
   increaseMaxNumberOfOpenFiles: true
   resizeRootPartition: false
   mountAllUnmountedDisks: true
 }
}


######################################################
#
# A list of instance types to use for group of nodes or management services
#

instances {

    adminnode {
        type: m4.2xlarge   # requires an HVM AMI
	 ebsVolumeCount : 1
        ebsVolumeType: sc1 # specify either st1, sc1 or gp2 volume type
        ebsVolumeSizeGiB: 900

        #image: ami-HVM-REPLACE-ME
        #image: ami-6d1c2007
        image:  ${?image}
	# SPOT option
        #useSpotInstances: true
        #spotBidUSDPerHr: 0.10 # Can be set/overridden per instance group

        #
        # Name of the IAM Role to use for this instance type
        # http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html
        #

        # iamProfileName: iam-profile-REPLACE-ME

        tags {
            owner: ${?USER}
        }




        bootstrapScript: """#!/bin/sh

# This is an embedded bootstrap script that runs as root and can be used to customize
# the instances immediately after boot and before any other Cloudera Director action

# If the exit code is not zero Cloudera Director will automatically retry

yum install -y wget
yum install -y git
yum remove *openjdk*
cd /tmp
wget http://archive.cloudera.com/director/redhat/7/x86_64/director/2.1.0/RPMS/x86_64/oracle-j2sdk1.8-1.8.0+update60-1.x86_64.rpm
rpm -ivh /tmp/oracle-j2sdk1.8-1.8.0+update60-1.x86_64.rpm
# end of java8 install
#
#  get the CSDs we want
wget http://nightly.streamsets.com.s3-us-west-2.amazonaws.com/datacollector/3.4/3.4.1/csd/STREAMSETS-3.4.1.jar


echo 'Hello World!'
exit 0

"""

        #

    }

    datanode {
        type: m5.4xlarge
	#  use new r image that has 16 core, 128gb ram for $.9 per hr
        # fails - lack of hvm support type: r5a.4xlarge
        #image: ami-HVM-REPLACE-ME
        #image: ami-6d1c2007
        image:  ${?image}
        ebsVolumeCount: 8
        ebsVolumeType: sc1 # specify either st1, sc1 or gp2 volume type
        ebsVolumeSizeGiB: 1100
	# SPOT option
        #useSpotInstances: true
        #spotBidUSDPerHr: 0.10 # Can be set/overridden per instance group


        tags {
            owner: ${?USER}
        }



        bootstrapScript: """#!/bin/sh

# This is an embedded bootstrap script that runs as root and can be used to customize
# the instances immediately after boot and before any other Cloudera Director action

# If the exit code is not zero Cloudera Director will automatically retry

yum install -y wget
yum install -y git
yum remove *openjdk*
cd /tmp
wget http://archive.cloudera.com/director/redhat/7/x86_64/director/2.1.0/RPMS/x86_64/oracle-j2sdk1.8-1.8.0+update60-1.x86_64.rpm
rpm -ivh /tmp/oracle-j2sdk1.8-1.8.0+update60-1.x86_64.rpm
# end of java8 install


echo 'Hello World!'
exit 0

"""
    }
}

#
# Configuration for Cloudera Manager. Cloudera Director can use an existing instance
# or bootstrap everything from scratch for a new cluster
#

cloudera-manager {

    instance: ${instances.adminnode} {
        tags {
            application: "Cloudera Manager 5"
        }
    }

    #
    # Automatically activate 60-Day Cloudera Enterprise Trial
    #

    enableEnterpriseTrial: true

    # Set up TLS connections automatically between Cloudera Director and Cloudera Manager,
    # as well as among the cluster services. Automatic TLS includes installation of
    # unlimited strength JCE policy files (see unlimitedJce).
    #

     tlsEnabled: true

    #
    # Pass TLS configuration properties to Cloudera Manager to refine how automatic TLS
    # is configured. All TLS configuration properties are optional and have sane defaults.
    # Additional properties are available beyond those listed here.
    #

    # tlsConfigurationProperties {
    #    subject_suffix: "O=example.com,L=Cityville,ST=CA,C=US"
    #    ca_sig_hash_algo: "SHA512"
    #    email_address: "name@example.com"
    # }



    javaInstallationStrategy: NONE     #Configure Java 8 on the cluster with a script

  csds: [
    "http://archive.cloudera.com/spark2/csd/SPARK2_ON_YARN-2.3.0.cloudera4.jar"
    
  ]


}

#
# Cluster description
#

cluster {

   parcelRepositories: ["http://archive.cloudera.com/cdh5/parcels/5.15.1/",
                         "http://archive.cloudera.com/kafka/parcels/3.1.0.35/",
                        "http://archive.cloudera.com/spark2/parcels/2.3.0.cloudera4/"]

    # List the products and their versions that need to be installed.
    # These products must have a corresponding parcel in the parcelRepositories
    # configured above. The specified version will be used to find a suitable
    # parcel. Specifying a version that points to more than one parcel among
    # those available will result in a configuration error. Specify more granular
    # versions to avoid conflicts.

    products {
      CDH: 5 # includes Impala and Spark
      SPARK2: 2
      KAFKA: 3
      }

    services: [HDFS, YARN, ZOOKEEPER,  HIVE, OOZIE, HUE,
	  IMPALA, SPARK_ON_YARN, SPARK2_ON_YARN, KAFKA,
	  KUDU
              ] 
# HBASE , SPARK2_ON_YARN, KUDU ]

   master1 {
        count: 1
        instance: ${instances.adminnode}
        tags {
           group: master
        }
        roles {
            HDFS: [NAMENODE, BALANCER, HTTPFS, GATEWAY]
            YARN: [RESOURCEMANAGER,  GATEWAY]
            SPARK_ON_YARN: [SPARK_YARN_HISTORY_SERVER, GATEWAY]
            SPARK2_ON_YARN: [SPARK2_YARN_HISTORY_SERVER, GATEWAY]
            KAFKA: [KAFKA_BROKER]
            KUDU: [KUDU_MASTER]
            ZOOKEEPER: [SERVER]
            HIVE: [GATEWAY]
        }



configs {

        KUDU {
            KUDU_MASTER {
                # The master rarely performs IO. If fs_data_dirs is unset, it will
                # use the same directory as fs_wal_dir
                fs_wal_dir: "/data0/kudu/masterwal"
                fs_data_dirs: "/data1/kudu/master"
            }
         }
      }


    }

   master2 {
        count: 1
        instance: ${instances.adminnode}
        tags {
           group: master
        }
        roles {
            HDFS: [ SECONDARYNAMENODE,  GATEWAY]
            YARN: [ JOBHISTORY, GATEWAY]
            SPARK_ON_YARN: [ GATEWAY]
            SPARK2_ON_YARN: [ GATEWAY]
            ZOOKEEPER: [SERVER]
	    KAFKA: [KAFKA_BROKER]
            HIVE: [GATEWAY]
        }
    }

   master3 {
        count: 1
        instance: ${instances.adminnode}
        tags {
           group: master
        }
        roles {
            HDFS: [ GATEWAY]
            YARN: [ GATEWAY]
            SPARK_ON_YARN: [ GATEWAY]
            SPARK2_ON_YARN: [ GATEWAY]
            IMPALA: [CATALOGSERVER, STATESTORE]
            ZOOKEEPER: [SERVER]
	    KAFKA: [KAFKA_BROKER]
            HIVE: [HIVESERVER2, HIVEMETASTORE, GATEWAY]
            OOZIE: [OOZIE_SERVER]
        }
    }
  
   gateways {
        count: 1
        instance: ${instances.adminnode}
        tags {
           group: mygw
        }
        roles {
            HDFS: [ GATEWAY]
            YARN: [ GATEWAY]
            SPARK_ON_YARN: [ GATEWAY]
            SPARK2_ON_YARN: [ GATEWAY]
            HIVE: [ GATEWAY]
            HUE: [HUE_SERVER]
        }
    }



    workers {
        count: 3
        instance: ${instances.datanode}
        tags {
           group: worker
        }
        roles {
            HDFS: [DATANODE]
            YARN: [NODEMANAGER]
            IMPALA: [IMPALAD]
	     SPARK_ON_YARN: [GATEWAY]
	     SPARK2_ON_YARN: [GATEWAY]
	   KUDU: [KUDU_TSERVER]
        }


configs {
        KUDU {
          KUDU_TSERVER {
            # Set fs_wal_dir to an SSD drive (if exists) for better performance.
            # Set fs_data_dirs to a comma-separated string containing all remaining
            # disk drives, solid state or otherwise.
            # If there are multiple drives in the machine, it's best to ensure that
            # the WAL directory is not located on the same disk as a tserver data
            # directory.
            fs_wal_dir: "/data0/kudu/tabletwal"
            fs_data_dirs: "/data1/kudu/tablet"
          }
        }
      }


    }
#
#
#
#
#  this works ok
   cdswn {
        count: 1
        instance: ${instances.adminnode}
        tags {
           group: cdswg
        }
        roles {
            HDFS: [ GATEWAY]
            YARN: [ GATEWAY]
            SPARK_ON_YARN: [ GATEWAY]
	     SPARK2_ON_YARN: [GATEWAY]
           HIVE: [ GATEWAY]
       }
    }

#    nodes {
#        count: 4
#        instance: ${instances.datanode}
#    }

    postCreateScripts: ["""#!/bin/sh

# This is an embedded post creation script script that runs as root and can be used to
# customize the cluster after it has been created.

# If the exit code is not zero Cloudera Director will fail

# install java8
#
yum install -y wget
yum install -y git
yum remove *openjdk*
cd /tmp
wget http://archive.cloudera.com/director/redhat/7/x86_64/director/2.1.0/RPMS/x86_64/oracle-j2sdk1.8-1.8.0+update60-1.x86_64.rpm
rpm -ivh /tmp/oracle-j2sdk1.8-1.8.0+update60-1.x86_64.rpm
# end of java8 install
#
#
echo 'Hello World!'
exit 0
    """,
    """#!/bin/bash

# Additionally, multiple post creation scripts can be supplied.  They will run in the
# order they are listed here.
# 
#
# Additionally, multiple post creation scripts can be supplied.  They will run in the
# order they are listed here.

sudo su - hdfs -c 'hadoop fs -mkdir /user/ec2-user'
sudo su - hdfs -c 'hadoop fs -chown ec2-user:ec2-user /user/ec2-user'

# copyright 2016 (c) Martin Lurie
# sample code - not supported
#
## RESET
#sudo su - centos -c "impala-shell  -i $(hostname):21000 <<eoj
#drop table if exists inpatient;
#drop table if exists inpatientsnappyparquet;
#eoj"
#
#sudo su - centos -c "hadoop fs -rm -r inpatient"
#sudo su - centos -c "rm Inpatient_Data_2012_CSV.zip"
#sudo su - centos -c "rm Medicare_Hospital_Inpatient_PUF_Methodology_2014-05-30.pdf"
#sudo su - centos -c "rm Medicare_Provider_Charge_Inpatient_DRG100_FY2012.csv"
#
## RUN DEMO 
#
#sudo su - centos -c "wget https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Downloads/Inpatient_Data_2012_CSV.zip"
#sudo su - centos -c "unzip Inpatient_Data_2012_CSV.zip "
#sudo su - centos -c "head Medicare_Provider_Charge_Inpatient_DRG100_FY2012.csv"
#sudo su - centos -c "hadoop fs -mkdir inpatient"
#sudo su - centos -c "hadoop fs -put Medicare_Provider_Charge_Inpatient_DRG100_FY2012.csv inpatient"
##
## DRG Definition,Provider Id,Provider Name,Provider Street Address,Provider City,Provider State,Provider Zip Code,Hospital Referral Region (HRR) Description,Total Discharges,Average Covered Charges,Average Total Payments,Average Medicare Payments
## 039 - EXTRACRANIAL PROCEDURES W/O CC/MCC,10001,SOUTHEAST ALABAMA MEDICAL CENTER,1108 ROSS CLARK CIRCLE,DOTHAN,AL,36301,AL - Dothan,95,37467.95789,5525.673684,4485.873684
## yes, there are some bad rows with too many commas
#
#sudo su - centos -c "impala-shell  -i $(hostname):21000  <<eoj
#drop table if exists inpatient;
#create external table inpatient (
#DRGDefinition string,
#ProviderId string,
#ProviderName string,
#ProviderStreetAddress string,
#ProviderCity string,
#ProviderState string,
#ProviderZipCode string,
#HospitalReferralRegionHRRDescription string,
#TotalDischarges decimal(12,5),
#AverageCoveredCharges decimal(12,6),
#AverageTotalPayments decimal(12,6),
#AverageMedicarePayments decimal(12,6)
#)
#COMMENT 'source https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Inpatient2012.html'
#ROW FORMAT DELIMITED 
#  FIELDS TERMINATED BY ',' 
#LOCATION
#  '/user/centos/inpatient'
#;
#
#select count(*) from inpatient;
#select * from inpatient limit 5;
#
#drop table if exists inpatientsnappyparquet;
#create table inpatientsnappyparquet as select * from inpatient;
#compute stats inpatientsnappyparquet;
#select sum( AverageCoveredCharges) , sum (AverageTotalPayments) , sum ( AverageMedicarePayments) from inpatientsnappyparquet;
#
#
#eoj"




echo "this script ran as user $(id)"

exit 0
    """]
}
